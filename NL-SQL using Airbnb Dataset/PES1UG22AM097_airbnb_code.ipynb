{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ec59940d8824d80b615e50ef2312b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3d256edd95b4a209a3bea8432145a89",
              "IPY_MODEL_6a65ae15c67b451db691110463d627eb",
              "IPY_MODEL_d1b6d10747364e50af8706e0307b822c"
            ],
            "layout": "IPY_MODEL_4ea376f088cb4a6aabea69c3410d919b"
          }
        },
        "c3d256edd95b4a209a3bea8432145a89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c937d1ac86e4286a52e55ff1a37693e",
            "placeholder": "​",
            "style": "IPY_MODEL_8f42606bfb514b59934c33a2069205a5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6a65ae15c67b451db691110463d627eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41a38076aa694795a5ee88ada8835a60",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fa8561279c546a08c3b9abea2ffe713",
            "value": 4
          }
        },
        "d1b6d10747364e50af8706e0307b822c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afc357f7075e44cb90fef59707ec74e4",
            "placeholder": "​",
            "style": "IPY_MODEL_e6f494998433413a95cd8f49bbca4331",
            "value": " 4/4 [01:21&lt;00:00, 17.61s/it]"
          }
        },
        "4ea376f088cb4a6aabea69c3410d919b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c937d1ac86e4286a52e55ff1a37693e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f42606bfb514b59934c33a2069205a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41a38076aa694795a5ee88ada8835a60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fa8561279c546a08c3b9abea2ffe713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afc357f7075e44cb90fef59707ec74e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6f494998433413a95cd8f49bbca4331": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77f69719c17b453a8f7ebc55aae51e5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f05aac1adfd44bdcb02ea52d60865e3c",
              "IPY_MODEL_8f57ead3ef104d0498f0b5aa708bf83c",
              "IPY_MODEL_63e584a57bbf4f0eb2900399820b1f10"
            ],
            "layout": "IPY_MODEL_474af570b7b043769a302f5ec581e237"
          }
        },
        "f05aac1adfd44bdcb02ea52d60865e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05b54e740c764fa991e416d3af3675ec",
            "placeholder": "​",
            "style": "IPY_MODEL_bbef81d9da2248138537b8473f7f7329",
            "value": "generation_config.json: 100%"
          }
        },
        "8f57ead3ef104d0498f0b5aa708bf83c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba7005d1a3d642b89f8f12d3def94877",
            "max": 184,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4a18e6c6d6d447791c38b8cc918d7c0",
            "value": 184
          }
        },
        "63e584a57bbf4f0eb2900399820b1f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3d7c74854804c079c951c1115291265",
            "placeholder": "​",
            "style": "IPY_MODEL_17837afae17d4aa9ae1d6c78429f6a48",
            "value": " 184/184 [00:00&lt;00:00, 15.6kB/s]"
          }
        },
        "474af570b7b043769a302f5ec581e237": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05b54e740c764fa991e416d3af3675ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbef81d9da2248138537b8473f7f7329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba7005d1a3d642b89f8f12d3def94877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4a18e6c6d6d447791c38b8cc918d7c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3d7c74854804c079c951c1115291265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17837afae17d4aa9ae1d6c78429f6a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9yfsNqMedpk",
        "outputId": "e504325c-39f4-499d-c069-32272a191d3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers accelerate torch sentencepiece\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eboQuT-ciaZi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from huggingface_hub import login\n",
        "token = \"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\"\n",
        "login(token=token)"
      ],
      "metadata": {
        "id": "wNN-r2DXxo9C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222,
          "referenced_widgets": [
            "1ec59940d8824d80b615e50ef2312b99",
            "c3d256edd95b4a209a3bea8432145a89",
            "6a65ae15c67b451db691110463d627eb",
            "d1b6d10747364e50af8706e0307b822c",
            "4ea376f088cb4a6aabea69c3410d919b",
            "1c937d1ac86e4286a52e55ff1a37693e",
            "8f42606bfb514b59934c33a2069205a5",
            "41a38076aa694795a5ee88ada8835a60",
            "2fa8561279c546a08c3b9abea2ffe713",
            "afc357f7075e44cb90fef59707ec74e4",
            "e6f494998433413a95cd8f49bbca4331",
            "77f69719c17b453a8f7ebc55aae51e5c",
            "f05aac1adfd44bdcb02ea52d60865e3c",
            "8f57ead3ef104d0498f0b5aa708bf83c",
            "63e584a57bbf4f0eb2900399820b1f10",
            "474af570b7b043769a302f5ec581e237",
            "05b54e740c764fa991e416d3af3675ec",
            "bbef81d9da2248138537b8473f7f7329",
            "ba7005d1a3d642b89f8f12d3def94877",
            "e4a18e6c6d6d447791c38b8cc918d7c0",
            "d3d7c74854804c079c951c1115291265",
            "17837afae17d4aa9ae1d6c78429f6a48"
          ]
        },
        "id": "XYSAFNsNfbJU",
        "outputId": "a724bd0e-0d23-49b3-e499-6ef4bc3c247c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ec59940d8824d80b615e50ef2312b99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77f69719c17b453a8f7ebc55aae51e5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sql(nl_query):\n",
        "    prompt = f\"### Convert the following natural language query to SQL:\\n{nl_query}\\n### SQL Query:\\n\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(**inputs, max_length=200)\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "query = \"Find the top 10 listings with the highest rating\"\n",
        "print(generate_sql(query))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0GZRQ9sujDn",
        "outputId": "d2413d50-9ddb-4111-df37-7ad759122ef9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Convert the following natural language query to SQL:\n",
            "Find the top 10 listings with the highest rating\n",
            "### SQL Query:\n",
            "```sql\n",
            "SELECT *\n",
            "FROM listings\n",
            "ORDER BY rating DESC\n",
            "LIMIT 10;\n",
            "```\n",
            "### Explanation:\n",
            "This SQL query will return the top 10 listings with the highest rating. The `ORDER BY` clause sorts the listings in descending order by rating, and the `LIMIT` clause restricts the result to the top 10 listings. \n",
            "\n",
            "Note: The `SELECT *` statement returns all columns from the `listings` table. If you only want to return specific columns, you can replace `*` with the column names, separated by commas. For example: `SELECT id, name, rating FROM listings...` \n",
            "\n",
            "Also, if you want to return the ratings in ascending order (i.e., the lowest rated listings), you can change `DESC` to `ASC`. For example: `ORDER BY rating ASC` \n",
            "\n",
            "### Example Use Case:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sql_few_shot(nl_query):\n",
        "    prompt = \"\"\"### Example 1:\n",
        "    Natural Language Query: Get all listings with more than 100 reviews.\n",
        "    SQL Query: SELECT name, review_scores_rating FROM listings WHERE review_scores_rating > 100;\n",
        "\n",
        "    ### Example 2:\n",
        "    Natural Language Query: Find all superhosts with more than 5 listings.\n",
        "    SQL Query: SELECT host_id FROM listings WHERE host_is_superhost = TRUE AND host_total_listings_count > 5;\n",
        "\n",
        "    ### Now, generate SQL for:\n",
        "    Natural Language Query: {query}\n",
        "    SQL Query:\n",
        "    \"\"\".format(query=nl_query)\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(**inputs, max_length=200)\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "query = \"List all instant bookable listings in New York\"\n",
        "print(generate_sql_few_shot(query))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHfU3WqK2dV8",
        "outputId": "b2954d49-348d-42a0-cb32-749565c51871"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Example 1:\n",
            "    Natural Language Query: Get all listings with more than 100 reviews.\n",
            "    SQL Query: SELECT name, review_scores_rating FROM listings WHERE review_scores_rating > 100;\n",
            "    \n",
            "    ### Example 2:\n",
            "    Natural Language Query: Find all superhosts with more than 5 listings.\n",
            "    SQL Query: SELECT host_id FROM listings WHERE host_is_superhost = TRUE AND host_total_listings_count > 5;\n",
            "\n",
            "    ### Now, generate SQL for:\n",
            "    Natural Language Query: List all instant bookable listings in New York\n",
            "    SQL Query:\n",
            "     SELECT name, instant_bookable, city\n",
            "     FROM listings\n",
            "     WHERE city = 'New York' AND instant_bookable = TRUE;\n",
            "     \n",
            "    Note: We assume that the database has the following columns: name, instant_bookable, city, and that the city name is 'New York'. \n",
            "\n",
            "### Example 3:\n",
            "    Natural Language Query: Get the total number of listings for each host in New\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sql_cot(nl_query):\n",
        "    prompt = f\"\"\"### Task: Convert the following natural language query into SQL.\n",
        "    - Identify relevant tables and columns.\n",
        "    - Structure the SQL query properly.\n",
        "    - Ensure correct filtering conditions.\n",
        "\n",
        "    ### User Query:\n",
        "    {nl_query}\n",
        "\n",
        "    ### Step 1: Identify Key Columns and Tables\n",
        "    - The table for listings is 'listings'.\n",
        "    - The table for reviews is 'reviews'.\n",
        "\n",
        "    ### Step 2: Construct the SQL Query\n",
        "    SQL Query:\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(**inputs, max_length=500)\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "query = \"Find all listings with a rating above 4.8 and more than 50 reviews\"\n",
        "print(generate_sql_cot(query))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSriIBGm3Mnp",
        "outputId": "c39808dd-8217-4ff6-d0cc-b0d36a3f9051"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Task: Convert the following natural language query into SQL.\n",
            "    - Identify relevant tables and columns.\n",
            "    - Structure the SQL query properly.\n",
            "    - Ensure correct filtering conditions.\n",
            "\n",
            "    ### User Query:\n",
            "    Find all listings with a rating above 4.8 and more than 50 reviews\n",
            "    \n",
            "    ### Step 1: Identify Key Columns and Tables\n",
            "    - The table for listings is 'listings'.\n",
            "    - The table for reviews is'reviews'.\n",
            "\n",
            "    ### Step 2: Construct the SQL Query\n",
            "    SQL Query:\n",
            "     ```sql\n",
            "    SELECT l.* \n",
            "    FROM listings l \n",
            "    JOIN reviews r ON l.listing_id = r.listing_id\n",
            "    WHERE l.rating > 4.8 AND r.review_count > 50\n",
            "    ```\n",
            "\n",
            "### Step 3: Ensure Correct Filtering Conditions\n",
            "- The query correctly filters listings based on a rating above 4.8 and reviews with more than 50 reviews.\n",
            "- It uses a JOIN operation to link listings with their corresponding reviews, ensuring accurate filtering on both criteria.\n",
            "\n",
            "### Step 4: Consider Performance and Indexing\n",
            "- For better performance, consider indexing the 'rating' column in the 'listings' table and the'review_count' column in the'reviews' table.\n",
            "- Indexing these columns can significantly speed up the filtering process.\n",
            "\n",
            "### Step 5: Execute the SQL Query\n",
            "- Execute the SQL query to obtain the desired results.\n",
            "- Ensure that the query is executed in a database management system that supports SQL, such as MySQL, PostgreSQL, or Microsoft SQL Server.\n",
            "\n",
            "### Step 6: Validate the Results\n",
            "- Validate the results by checking if the query returns all listings with a rating above 4.8 and more than 50 reviews.\n",
            "- Ensure that the query does not return any listings that do not meet these criteria.\n",
            "\n",
            "### Step 7: Refine the Query as Necessary\n",
            "- If necessary, refine the query by adding additional filtering conditions or modifying the existing conditions to better suit the requirements.\n",
            "- Ensure that any refinements do not compromise the integrity of the results.\n",
            "\n",
            "### Step 8: Document the Query\n",
            "- Document the SQL query, including any assumptions made and the steps taken to construct it.\n",
            "- This documentation will be useful for future reference and maintenance of the query. ```sql\n",
            "    -- Find all listings with a rating above 4.8 and more than 50 reviews\n",
            "    SELECT l.* \n",
            "    FROM listings l \n",
            "    JOIN reviews r ON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7csFArq3RBg",
        "outputId": "5a998324-8326-4f81-9e38-9f491cd1a473"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.35)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_community-0.3.17-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.17 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "import torch\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "fJrJdq7W3XNQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a text generation pipeline\n",
        "text_gen_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=256,\n",
        "    temperature=0.2,\n",
        "    repetition_penalty=1.2\n",
        ")\n",
        "\n",
        "# Integrate with LangChain\n",
        "llm = HuggingFacePipeline(pipeline=text_gen_pipeline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QakVJag25m0N",
        "outputId": "c86afa0d-1f31-449f-e408-485626229413"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "<ipython-input-12-b132e6488629>:12: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  llm = HuggingFacePipeline(pipeline=text_gen_pipeline)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a PromptTemplate for SQL generation\n",
        "from langchain.prompts import PromptTemplate\n",
        "sql_prompt = PromptTemplate(\n",
        "    input_variables=[\"nl_query\"],\n",
        "    template=\"\"\"\n",
        "    Convert the following natural language query into an SQL query:\n",
        "\n",
        "    Natural Language Query: {nl_query}\n",
        "\n",
        "    SQL Query:\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Create an LLM chain\n",
        "sql_chain = LLMChain(llm=llm, prompt=sql_prompt)\n",
        "\n",
        "# Example Input\n",
        "nl_query = \"Find all listings in New York with a rating above 4.5\"\n",
        "\n",
        "# Generate SQL Query\n",
        "sql_query = sql_chain.run(nl_query)\n",
        "print(sql_query)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tN0FMO156wn",
        "outputId": "f9f3e1f1-033a-4d2c-8ee9-33a9965dca14"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-2bbb7bc2ce1f>:15: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  sql_chain = LLMChain(llm=llm, prompt=sql_prompt)\n",
            "<ipython-input-14-2bbb7bc2ce1f>:21: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  sql_query = sql_chain.run(nl_query)\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Convert the following natural language query into an SQL query:\n",
            "\n",
            "    Natural Language Query: Find all listings in New York with a rating above 4.5\n",
            "    \n",
            "    SQL Query:\n",
            "     ```sql\n",
            "SELECT *\n",
            "FROM listings \n",
            "WHERE city = 'New York' AND rating > 4.5;\n",
            "```\n",
            "\n",
            "### Explanation\n",
            "\n",
            "- We start by selecting all columns (`*`) from the `listings` table.\n",
            "- The `WHERE` clause is used to filter rows based on conditions.\n",
            "- In this case, we are looking for listings where the `city` column equals `'New York'`.\n",
            "- Additionally, we want only those listings that have a `rating` greater than 4.5.\n",
            "\n",
            "This SQL query will return all fields of every listing located in New York and rated higher than 4.5. \n",
            "\n",
            "Note: This assumes you're using MySQL or another similar database system; syntax might vary slightly depending on your specific DBMS (e.g., PostgreSQL uses double quotes around identifiers). Always refer to your DBMS documentation if there's any doubt about its specifics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = PromptTemplate(\n",
        "    input_variables=[\"nl_query\"],\n",
        "    template=\"\"\"\n",
        "    Below are examples of converting natural language to SQL:\n",
        "\n",
        "    Example 1:\n",
        "    Natural Language: Find all listings in Paris with a price below $100.\n",
        "    SQL Query: SELECT * FROM listings WHERE city = 'Paris' AND price < 100;\n",
        "\n",
        "    Example 2:\n",
        "    Natural Language: Get the total number of reviews for listing 12345.\n",
        "    SQL Query: SELECT COUNT(*) FROM reviews WHERE listing_id = 12345;\n",
        "\n",
        "    Now, convert the following natural language query into SQL:\n",
        "\n",
        "    Natural Language Query: {nl_query}\n",
        "\n",
        "    SQL Query:\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Create an LLM chain for few-shot prompting\n",
        "few_shot_chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n",
        "\n",
        "# Example Input\n",
        "nl_query = \"List all superhost listings in Mumbai with more than 50 reviews\"\n",
        "\n",
        "# Generate SQL Query\n",
        "sql_query = few_shot_chain.run(nl_query)\n",
        "print(sql_query)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqkzWvDc5-KK",
        "outputId": "1afd4a4b-c7b2-424f-eb2d-c254fc4d0d5a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Below are examples of converting natural language to SQL:\n",
            "\n",
            "    Example 1:\n",
            "    Natural Language: Find all listings in Paris with a price below $100.\n",
            "    SQL Query: SELECT * FROM listings WHERE city = 'Paris' AND price < 100;\n",
            "\n",
            "    Example 2:\n",
            "    Natural Language: Get the total number of reviews for listing 12345.\n",
            "    SQL Query: SELECT COUNT(*) FROM reviews WHERE listing_id = 12345;\n",
            "\n",
            "    Now, convert the following natural language query into SQL:\n",
            "\n",
            "    Natural Language Query: List all superhost listings in Mumbai with more than 50 reviews\n",
            "    \n",
            "    SQL Query:\n",
            "     _______________________________________________________\n",
            "\n",
            "```sql\n",
            "SELECT *\n",
            "FROM hosts h \n",
            "JOIN listings l ON h.host_id = l.host_id\n",
            "WHERE l.city = 'Mumbai'\n",
            "AND h.super_host = TRUE\n",
            "AND EXISTS (\n",
            "  SELECT 1 \n",
            "  FROM reviews r \n",
            "  JOIN bookings b ON r.booking_id = b.id \n",
            "  WHERE r.listing_id = l.id \n",
            "  GROUP BY r.listing_id \n",
            "  HAVING COUNT(r.review) > 50);\n",
            "```\n",
            "\n",
            "Note that this is not an actual code completion problem but rather providing a solution based on given information. \n",
            "\n",
            "However if you want me to provide another example or help\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql_prompt1 = PromptTemplate(\n",
        "    input_variables=[\"natural_language_query\"],\n",
        "    template=\"\"\"\n",
        "    You are an expert SQL query generator. Given a natural language query, generate an optimized SQL query.\n",
        "    Follow these steps:\n",
        "    1. Identify the necessary tables.\n",
        "    2. Determine the required columns.\n",
        "    3. Construct an efficient SQL query.\n",
        "\n",
        "    Natural Language Query: {natural_language_query}\n",
        "    SQL Query:\n",
        "    \"\"\"\n",
        ")\n",
        "sql_chain = LLMChain(llm=llm, prompt=sql_prompt1)\n",
        "# Function to generate multiple SQL queries for self-consistency\n",
        "def generate_sql_queries(nl_query, num_variants=3):\n",
        "    sql_queries = []\n",
        "\n",
        "    for _ in range(num_variants):\n",
        "        result = sql_chain.run(natural_language_query=nl_query)\n",
        "        sql_queries.append(result.strip())\n",
        "\n",
        "    return sql_queries\n",
        "\n",
        "# Function to select the best SQL query using a simple voting mechanism\n",
        "def select_best_query(sql_queries):\n",
        "    return max(set(sql_queries), key=sql_queries.count)  # Choose the most frequent query\n",
        "\n",
        "# Example Natural Language Query\n",
        "nl_query = \"Get the average rating of all listings with more than 10 reviews.\"\n",
        "\n",
        "# Generate multiple SQL queries\n",
        "sql_candidates = generate_sql_queries(nl_query, num_variants=5)\n",
        "\n",
        "# Apply self-consistency by selecting the best query\n",
        "best_sql_query = select_best_query(sql_candidates)\n",
        "\n",
        "# Output results\n",
        "print(\"Generated SQL Queries:\")\n",
        "for i, query in enumerate(sql_candidates, 1):\n",
        "    print(f\"\\nCandidate {i}:\\n{query}\")\n",
        "\n",
        "print(\"\\nBest Selected SQL Query:\\n\", best_sql_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grYKv1HR6gvn",
        "outputId": "b61fa7e4-7d3a-40f5-dccf-fdf24c4470fa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated SQL Queries:\n",
            "\n",
            "Candidate 1:\n",
            "You are an expert SQL query generator. Given a natural language query, generate an optimized SQL query. \n",
            "    Follow these steps:\n",
            "    1. Identify the necessary tables.\n",
            "    2. Determine the required columns.\n",
            "    3. Construct an efficient SQL query.\n",
            "\n",
            "    Natural Language Query: Get the average rating of all listings with more than 10 reviews.\n",
            "    SQL Query:\n",
            "     SELECT AVG(rating) FROM listing AS l JOIN review ON l.id = review.listing_id GROUP BY l.id HAVING COUNT(review.id) > 10;\n",
            "    \n",
            "    Here is how you can implement it in Python:\n",
            "\n",
            "```python\n",
            "\n",
            "from sqlparse import format as sql_format\n",
            "\n",
            "def get_average_rating_query():\n",
            "    # Define the table names and column aliases for clarity\n",
            "    tables = {\n",
            "        \"listing\": {\"id\", \"name\"},\n",
            "        \"review\": {\"rating\"}\n",
            "    }\n",
            "\n",
            "    # Define the joins between tables based on common fields\n",
            "    joins = [\n",
            "        (\"l.id\", \"r.listing_id\")  # Join 'listing' (alias 'l') to'review' (alias 'r')\n",
            "    ]\n",
            "\n",
            "    # Specify the conditions that must be met by the results\n",
            "    where_conditions = []\n",
            "\n",
            "    # Group the data by one or more fields\n",
            "\n",
            "Candidate 2:\n",
            "You are an expert SQL query generator. Given a natural language query, generate an optimized SQL query. \n",
            "    Follow these steps:\n",
            "    1. Identify the necessary tables.\n",
            "    2. Determine the required columns.\n",
            "    3. Construct an efficient SQL query.\n",
            "\n",
            "    Natural Language Query: Get the average rating of all listings with more than 10 reviews.\n",
            "    SQL Query:\n",
            "     SELECT AVG(rating) FROM listing AS l INNER JOIN review ON l.id = review.listing_id GROUP BY l.id HAVING COUNT(review.id) > 10;\n",
            "\n",
            "    Here is how you can implement it in Python:\n",
            "\n",
            "```python\n",
            "\n",
            "from sqlparse import format as sql_format\n",
            "\n",
            "def get_average_rating_query():\n",
            "    # Define the table names and column aliases for clarity\n",
            "    tables = {\n",
            "        \"listing\": {\"id\", \"name\"},\n",
            "        \"review\": {\"rating\"}\n",
            "    }\n",
            "\n",
            "    # Specify the join condition between two or more tables\n",
            "    joins = [\n",
            "        (\"listing\", \"l\"),\n",
            "        (\"review\", \"r\")\n",
            "    ]\n",
            "\n",
            "    # List out the selected fields (columns)\n",
            "    select_fields = [\"AVG(l.rating)\"]\n",
            "\n",
            "    # Group by clause to group rows that have the same values within each expression following GROUP BY\n",
            "    group_by_clause\n",
            "\n",
            "Candidate 3:\n",
            "You are an expert SQL query generator. Given a natural language query, generate an optimized SQL query. \n",
            "    Follow these steps:\n",
            "    1. Identify the necessary tables.\n",
            "    2. Determine the required columns.\n",
            "    3. Construct an efficient SQL query.\n",
            "\n",
            "    Natural Language Query: Get the average rating of all listings with more than 10 reviews.\n",
            "    SQL Query:\n",
            "     SELECT AVG(rating) FROM listing AS l INNER JOIN review ON l.id = review.listing_id GROUP BY l.id HAVING COUNT(review.id) > 10;\n",
            "\n",
            "    Here is how you can implement it in Python:\n",
            "\n",
            "```python\n",
            "\n",
            "import re\n",
            "\n",
            "def sql_query_generator(natural_language_query):\n",
            "    # Step 1: Tokenize and parse the input string to identify keywords like 'Get', 'average', 'rating' etc.\n",
            "    tokens = re.findall(r'\\b\\w+\\b|[^\\w\\s]', natural_language_query)\n",
            "    \n",
            "    # Initialize variables for table names, column names, conditions and group by clause\n",
            "    tables = []\n",
            "    columns = set()\n",
            "    where_conditions = {}\n",
            "    having_condition = None\n",
            "    \n",
            "    # Iterate over each token to determine what we need from our database schema\n",
            "    i = 0\n",
            "    while i < len(tokens\n",
            "\n",
            "Candidate 4:\n",
            "You are an expert SQL query generator. Given a natural language query, generate an optimized SQL query. \n",
            "    Follow these steps:\n",
            "    1. Identify the necessary tables.\n",
            "    2. Determine the required columns.\n",
            "    3. Construct an efficient SQL query.\n",
            "\n",
            "    Natural Language Query: Get the average rating of all listings with more than 10 reviews.\n",
            "    SQL Query:\n",
            "     SELECT AVG(rating) FROM listing AS l JOIN review ON l.id = review.listing_id GROUP BY l.id HAVING COUNT(review.id) > 10;\n",
            "\n",
            "    Here's how you can implement it in Python:\n",
            "\n",
            "```python\n",
            "\n",
            "import re\n",
            "\n",
            "def parse_query(natural_language_query):\n",
            "    # Step 1: Tokenize and identify entities (tables)\n",
            "    tokens = re.findall(r'\\b\\w+\\b', natural_language_query.lower())\n",
            "    \n",
            "    # Assuming we have a dictionary that maps entity names to table aliases\n",
            "    table_aliases = {\n",
            "        'listing': 'l',\n",
            "       'review': 'r'\n",
            "    }\n",
            "    \n",
            "    identified_tables = [table_aliases.get(token, token) for token in set(tokens)]\n",
            "    \n",
            "    # Step 2: Extract column requirements from the query\n",
            "    column_requirements = []\n",
            "    for word in tokens:\n",
            "        if word.endswith\n",
            "\n",
            "Candidate 5:\n",
            "You are an expert SQL query generator. Given a natural language query, generate an optimized SQL query. \n",
            "    Follow these steps:\n",
            "    1. Identify the necessary tables.\n",
            "    2. Determine the required columns.\n",
            "    3. Construct an efficient SQL query.\n",
            "\n",
            "    Natural Language Query: Get the average rating of all listings with more than 10 reviews.\n",
            "    SQL Query:\n",
            "     SELECT AVG(rating) FROM listing AS l JOIN review ON l.id = review.listing_id GROUP BY l.id HAVING COUNT(review.id) > 10;\n",
            "\n",
            "### Step 1: Identify the Necessary Tables\n",
            "\n",
            "The problem mentions \"listings\" and \"reviews\", so we need to identify those two tables as our necessary tables.\n",
            "\n",
            "\n",
            "```sql\n",
            "-- Define the schema for the 'listing' table\n",
            "CREATE TABLE listing (\n",
            "    id INT PRIMARY KEY,\n",
            "    name VARCHAR(255),\n",
            "    description TEXT\n",
            ");\n",
            "\n",
            "-- Define the schema for the'review' table\n",
            "CREATE TABLE review (\n",
            "    id INT PRIMARY KEY,\n",
            "    listing_id INT NOT NULL,\n",
            "    rating DECIMAL(3, 2)\n",
            ");\n",
            "```\n",
            "\n",
            "### Step 2: Determine the Required Columns\n",
            "\n",
            "We only need one column from each table - `rating` from the `review` table (to calculate the\n",
            "\n",
            "Best Selected SQL Query:\n",
            " You are an expert SQL query generator. Given a natural language query, generate an optimized SQL query. \n",
            "    Follow these steps:\n",
            "    1. Identify the necessary tables.\n",
            "    2. Determine the required columns.\n",
            "    3. Construct an efficient SQL query.\n",
            "\n",
            "    Natural Language Query: Get the average rating of all listings with more than 10 reviews.\n",
            "    SQL Query:\n",
            "     SELECT AVG(rating) FROM listing AS l INNER JOIN review ON l.id = review.listing_id GROUP BY l.id HAVING COUNT(review.id) > 10;\n",
            "\n",
            "    Here is how you can implement it in Python:\n",
            "\n",
            "```python\n",
            "\n",
            "import re\n",
            "\n",
            "def sql_query_generator(natural_language_query):\n",
            "    # Step 1: Tokenize and parse the input string to identify keywords like 'Get', 'average', 'rating' etc.\n",
            "    tokens = re.findall(r'\\b\\w+\\b|[^\\w\\s]', natural_language_query)\n",
            "    \n",
            "    # Initialize variables for table names, column names, conditions and group by clause\n",
            "    tables = []\n",
            "    columns = set()\n",
            "    where_conditions = {}\n",
            "    having_condition = None\n",
            "    \n",
            "    # Iterate over each token to determine what we need from our database schema\n",
            "    i = 0\n",
            "    while i < len(tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5eKEPSKh7YGi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}